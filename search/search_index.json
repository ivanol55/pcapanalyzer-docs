{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PCAPAnalyzer project documentation Welcome! This is the site where you'll find reference documentation for all things PCAPAnalyzer , from frontend usage, to backend management, to API interaction. Documentation structure getting started - your starting point prerequisites - what you need to setup first installation - let's set you up main server - The base install agent - gather data from other sources post-install - what you should know frontend - Where you'll find documentation about UI interaction and features. login - web authentication homepage - a quick summary packetStream - data filtering dataGlance - quick, usually needed info queryRunner - roll your own SQL dbCreator - analyze your own pcaps database picker - manage database usage About - manage internal tokens User management - manage webUI users API management - manage API tokens backend .my.cnf - application information packetStream - constant data gathering PCAPAnalyzer IDS - get attack warnings by mail analysisGenerator - generate custom database reports API authentication - allowing requests endpoints - what can you do? dblist - listing databases rawnumbers - quick data for dashboards insights - dataGlance in JSON format reference - Quick query and answer manuals","title":"Home"},{"location":"#pcapanalyzer-project-documentation","text":"Welcome! This is the site where you'll find reference documentation for all things PCAPAnalyzer , from frontend usage, to backend management, to API interaction.","title":"PCAPAnalyzer project documentation"},{"location":"#documentation-structure","text":"getting started - your starting point prerequisites - what you need to setup first installation - let's set you up main server - The base install agent - gather data from other sources post-install - what you should know frontend - Where you'll find documentation about UI interaction and features. login - web authentication homepage - a quick summary packetStream - data filtering dataGlance - quick, usually needed info queryRunner - roll your own SQL dbCreator - analyze your own pcaps database picker - manage database usage About - manage internal tokens User management - manage webUI users API management - manage API tokens backend .my.cnf - application information packetStream - constant data gathering PCAPAnalyzer IDS - get attack warnings by mail analysisGenerator - generate custom database reports API authentication - allowing requests endpoints - what can you do? dblist - listing databases rawnumbers - quick data for dashboards insights - dataGlance in JSON format reference - Quick query and answer manuals","title":"Documentation structure"},{"location":"about/","text":"About this project This is the documentation for the PCAPAnalyzer project, created by Ivan Mendez , Sergi pellejero and Luis Portillo . All parts of this project, both this docummentation and the program itself, are licensed under the GNU General Public License v3 .","title":"About this project"},{"location":"about/#about-this-project","text":"This is the documentation for the PCAPAnalyzer project, created by Ivan Mendez , Sergi pellejero and Luis Portillo . All parts of this project, both this docummentation and the program itself, are licensed under the GNU General Public License v3 .","title":"About this project"},{"location":"api/authentication/","text":"Authentication As to not allow any unauthorized API requests, the PCAPAnalyzer API has implemented an authentication system. With every request, it needs to recieve a valid API key written into the request. If this is not provided, the server will answer with a 403 forbidden API answer as a status code. The api key needs to be sent as a GET parameter on the request with the key name apikey to be correctly picked up by the system, for example with something like curl https://{domain}/api/dblist.php?apikey=APIKEYVALUE where APIKEYVALUE is an API key you generated on the web frontend. Once a request is autheticated, it will go on to read your request. Depending on what you want to request, you may need to provide some more data.","title":"authentication"},{"location":"api/authentication/#authentication","text":"As to not allow any unauthorized API requests, the PCAPAnalyzer API has implemented an authentication system. With every request, it needs to recieve a valid API key written into the request. If this is not provided, the server will answer with a 403 forbidden API answer as a status code. The api key needs to be sent as a GET parameter on the request with the key name apikey to be correctly picked up by the system, for example with something like curl https://{domain}/api/dblist.php?apikey=APIKEYVALUE where APIKEYVALUE is an API key you generated on the web frontend. Once a request is autheticated, it will go on to read your request. Depending on what you want to request, you may need to provide some more data.","title":"Authentication"},{"location":"api/endpoints/","text":"# API endpoints You have different data points to request from different API endpoints. The currently available data endpoints are: dblist insights rawnumbers They are all set up as .php files, so to request, for example, the dblist API endpoint, you will need to rmake a request to dblist.php . The names provided in the titles are all the same as their endpoint file. Every database endpoint has a similar 2-part structure. first, a code which indicates the success or failure of the request, using the same codes as the http protocol, and then, the data requested, if any. In case of a failed request, the API endpoint will only return a status code in JSON . dblist The dblist endpoint allows you to see a list of the databases available for data requesting. you will only need to provide authentication to request data to this API endpoint. insights The insights API endpoint will provide you with the data seen on the dataGlance frontend page, but in a parseable JSON response format. To request data from this endpoint, you will need to send in: an API authentication token through apikey the database you want to query with a database UTM. rawnumbers The rawnumbers endpoint will return the data seen on the web frontend, the aggregated count data, for the database that you request it to, in a parseable JSON format. To request data from this endpoint, you will need to send in: an API authentication token through apikey the database you want to query with a database UTM. See the next page for reference examples.","title":"endpoints"},{"location":"api/endpoints/#dblist","text":"The dblist endpoint allows you to see a list of the databases available for data requesting. you will only need to provide authentication to request data to this API endpoint.","title":"dblist"},{"location":"api/endpoints/#insights","text":"The insights API endpoint will provide you with the data seen on the dataGlance frontend page, but in a parseable JSON response format. To request data from this endpoint, you will need to send in: an API authentication token through apikey the database you want to query with a database UTM.","title":"insights"},{"location":"api/endpoints/#rawnumbers","text":"The rawnumbers endpoint will return the data seen on the web frontend, the aggregated count data, for the database that you request it to, in a parseable JSON format. To request data from this endpoint, you will need to send in: an API authentication token through apikey the database you want to query with a database UTM. See the next page for reference examples.","title":"rawnumbers"},{"location":"api/reference/","text":"API reference Here you can find example queries and responses to the PCAPAnalyzer API endpoints dblist Request curl https://{domain}/api/dblist.php?apikey=42af1e890d3 Response { \"code\": 200, \"databases\": [ \"packetstream\", \"analysis_ssh\" ] } insights Request curl https://{domain}/api/insights.php?apikey=47d16be1c459&database=packetstream Response { \"code\": 200, \"privateips\": [ \"192.168.1.111\", \"192.168.1.99\", \"172.17.168.163\", \"172.17.16.225\" ], \"publicips\": [ \"216.58.201.170\", \"13.33.237.133\", \"151.101.134.214\", \"52.34.194.35\", \"216.58.209.74\", \"52.43.242.4\", \"93.176.183.102\", \"192.0.73.2\", \"142.250.184.161\", \"192.99.17.213\", \"45.148.10.66\" ], \"macaddresses\": [ \"33:33:ff:78:95:4f\", \"33:33:ff:38:2d:11\", \"33:33:00:00:00:02\", \"33:33:00:01:00:02\", \"33:33:00:00:00:16\", \"01:00:5e:00:00:fb\", \"ff:ff:ff:ff:ff:ff\", \"d8:61:94:e6:db:bf\", \"7c:d6:61:38:2d:11\", \"33:33:ff:ad:66:57\", \"38:22:e2:63:58:b6\", \"08:00:27:d1:62:8e\", \"4c:63:71:ad:66:57\", \"33:33:ff:e1:53:1d\", \"94:de:80:bc:71:45\", \"8c:e1:17:e5:f1:2e\", \"33:33:ff:63:58:b6\", \"33:33:00:00:00:01\", \"33:33:00:00:00:fb\", \"20:89:86:ae:3e:98\", \"e4:e1:30:78:95:4f\", \"88:29:9c:c5:3c:45\", \"01:00:5e:7f:ff:fa\" ], \"protocolsfound\": [ \"NBNS\", \"RTMP\", \"DHCPv6\", \"TLSv1\", \"DHCP\", \"ICMP\", \"SSH\", \"OCSP\", \"TCP\", \"MDNS\", \"TLSv1.2\", \"SSLv2\", \"PGSQL\", \"ARP\", \"ICMPv6\", \"SSDP\", \"DNS\", \"LLC\", \"TLSv1.3\" ], \"wellknownports\": [ \"80\", \"67\", \"443\", \"22\", \"547\", \"53\", \"137\" ], \"registeredports\": [ \"37026\", \"46671\", \"46944\", \"1935\", \"42440\", \"42526\", \"40110\", \"35364\", \"34742\", \"44793\", \"48748\", \"38674\", \"37317\", \"38352\", \"37826\", \"47926\", \"38530\", \"44602\", \"46764\", \"38100\", \"37563\", \"38532\", \"35293\", \"48906\", \"49066\", \"47280\", \"1900\", \"41822\", \"47668\", \"35557\" ] } rawnumbers Request curl https://{domain}/api/rawnumbers.php?apikey=47d16be1c459&database=packetstream Response { \"code\": 200, \"packetcount\": 198990, \"datasourcecount\": 3, \"externalipcount\": 75, \"maccount\": 23, \"multicastcount\": 139, \"protocolcount\": 19 }","title":"reference"},{"location":"api/reference/#api-reference","text":"Here you can find example queries and responses to the PCAPAnalyzer API endpoints","title":"API reference"},{"location":"api/reference/#dblist","text":"","title":"dblist"},{"location":"api/reference/#request","text":"curl https://{domain}/api/dblist.php?apikey=42af1e890d3","title":"Request"},{"location":"api/reference/#response","text":"{ \"code\": 200, \"databases\": [ \"packetstream\", \"analysis_ssh\" ] }","title":"Response"},{"location":"api/reference/#insights","text":"","title":"insights"},{"location":"api/reference/#request_1","text":"curl https://{domain}/api/insights.php?apikey=47d16be1c459&database=packetstream","title":"Request"},{"location":"api/reference/#response_1","text":"{ \"code\": 200, \"privateips\": [ \"192.168.1.111\", \"192.168.1.99\", \"172.17.168.163\", \"172.17.16.225\" ], \"publicips\": [ \"216.58.201.170\", \"13.33.237.133\", \"151.101.134.214\", \"52.34.194.35\", \"216.58.209.74\", \"52.43.242.4\", \"93.176.183.102\", \"192.0.73.2\", \"142.250.184.161\", \"192.99.17.213\", \"45.148.10.66\" ], \"macaddresses\": [ \"33:33:ff:78:95:4f\", \"33:33:ff:38:2d:11\", \"33:33:00:00:00:02\", \"33:33:00:01:00:02\", \"33:33:00:00:00:16\", \"01:00:5e:00:00:fb\", \"ff:ff:ff:ff:ff:ff\", \"d8:61:94:e6:db:bf\", \"7c:d6:61:38:2d:11\", \"33:33:ff:ad:66:57\", \"38:22:e2:63:58:b6\", \"08:00:27:d1:62:8e\", \"4c:63:71:ad:66:57\", \"33:33:ff:e1:53:1d\", \"94:de:80:bc:71:45\", \"8c:e1:17:e5:f1:2e\", \"33:33:ff:63:58:b6\", \"33:33:00:00:00:01\", \"33:33:00:00:00:fb\", \"20:89:86:ae:3e:98\", \"e4:e1:30:78:95:4f\", \"88:29:9c:c5:3c:45\", \"01:00:5e:7f:ff:fa\" ], \"protocolsfound\": [ \"NBNS\", \"RTMP\", \"DHCPv6\", \"TLSv1\", \"DHCP\", \"ICMP\", \"SSH\", \"OCSP\", \"TCP\", \"MDNS\", \"TLSv1.2\", \"SSLv2\", \"PGSQL\", \"ARP\", \"ICMPv6\", \"SSDP\", \"DNS\", \"LLC\", \"TLSv1.3\" ], \"wellknownports\": [ \"80\", \"67\", \"443\", \"22\", \"547\", \"53\", \"137\" ], \"registeredports\": [ \"37026\", \"46671\", \"46944\", \"1935\", \"42440\", \"42526\", \"40110\", \"35364\", \"34742\", \"44793\", \"48748\", \"38674\", \"37317\", \"38352\", \"37826\", \"47926\", \"38530\", \"44602\", \"46764\", \"38100\", \"37563\", \"38532\", \"35293\", \"48906\", \"49066\", \"47280\", \"1900\", \"41822\", \"47668\", \"35557\" ] }","title":"Response"},{"location":"api/reference/#rawnumbers","text":"","title":"rawnumbers"},{"location":"api/reference/#request_2","text":"curl https://{domain}/api/rawnumbers.php?apikey=47d16be1c459&database=packetstream","title":"Request"},{"location":"api/reference/#response_2","text":"{ \"code\": 200, \"packetcount\": 198990, \"datasourcecount\": 3, \"externalipcount\": 75, \"maccount\": 23, \"multicastcount\": 139, \"protocolcount\": 19 }","title":"Response"},{"location":"backend/analysis-generator/","text":"PCAPAnalyzer Analysus generator This is the backend code for the dbCreator frontend system. It packages all the necessary tools for you to generate new databases to analyze data on. you will find two folder structures, script and files Script Under the script folder you'll find the python code that runs through the process of generating the new database. It is essentially a compressed version of the packetstream data transformation workflow, as in, it reads .pcap files, in this case your uploaded ones, into csv files, it transforms them into standard contents, and puts them into a new database. files The files folder separates its workflow into two different folders: pcaps and csvs . on the first one, every time you create a new database, it creates a folder to store all the needed .pcap files inside of. Then the script reads them and, when transformed, moves the data into its proper csvs subfolder, where the system will read it into the database.","title":"analysisGenerator"},{"location":"backend/analysis-generator/#pcapanalyzer-analysus-generator","text":"This is the backend code for the dbCreator frontend system. It packages all the necessary tools for you to generate new databases to analyze data on. you will find two folder structures, script and files","title":"PCAPAnalyzer Analysus generator"},{"location":"backend/analysis-generator/#script","text":"Under the script folder you'll find the python code that runs through the process of generating the new database. It is essentially a compressed version of the packetstream data transformation workflow, as in, it reads .pcap files, in this case your uploaded ones, into csv files, it transforms them into standard contents, and puts them into a new database.","title":"Script"},{"location":"backend/analysis-generator/#files","text":"The files folder separates its workflow into two different folders: pcaps and csvs . on the first one, every time you create a new database, it creates a folder to store all the needed .pcap files inside of. Then the script reads them and, when transformed, moves the data into its proper csvs subfolder, where the system will read it into the database.","title":"files"},{"location":"backend/creds/","text":"Server credentials On the backend folder of your PCAPAnalyzer server install you'll see a file called .my.cnf . This file is the central authentication credential and variable source for the server install. Inside your file you will find five categories: client paths interfaces queryrunner credchecking client The client category tag stores declarations for data about the current client system: host : an IP address pointing to the IP address where your PostgreSQL PCAPAnalyzer instance is hosted on. user : the name that the system uses to login to the database for general tasks. password : the password for the general tasks user. database : the name of the main database, generally packetstream . machineid : a unique system name for the packetstream capture system to insert into its data. paths The path category tag stores the absolute system paths for needed directories: basedir : the absolute base filesystem directory where your PCAPAnalyzer install is located. interfaces The interfaces category tag stores data about the listening system for packetstream : interface : the interface that the packetstream system listens on. it can be set to any of the interfaces on the system, but it can only have one value. It cannot be set to any . queryrunner The queryrunner category tag stores information needed for the queryrunner side of the web frontend: selectuser : The username on the PostgreSQL system that is only allowed to select data, from all of the PCAPAnalyzer databases. selectpassword : the password configured on install for the user mentioned above. credchecking The credchecking category tag stores information needed to connect to the database that stores frontend accounts and API keys: user : the PostgreSQL install system user that can work with the pcapanalyzer_creds database to check and manage users and API keys. password : The PostgreSQL password for the user mentioned above. host : the database host where the PCAPAnalyzer install was made. Generally the same as the one on the client category tag. database : the name of the database where the system will look for credentials, generally pcapanalyzer_creds .","title":".my.cnf"},{"location":"backend/creds/#server-credentials","text":"On the backend folder of your PCAPAnalyzer server install you'll see a file called .my.cnf . This file is the central authentication credential and variable source for the server install. Inside your file you will find five categories: client paths interfaces queryrunner credchecking","title":"Server credentials"},{"location":"backend/creds/#client","text":"The client category tag stores declarations for data about the current client system: host : an IP address pointing to the IP address where your PostgreSQL PCAPAnalyzer instance is hosted on. user : the name that the system uses to login to the database for general tasks. password : the password for the general tasks user. database : the name of the main database, generally packetstream . machineid : a unique system name for the packetstream capture system to insert into its data.","title":"client"},{"location":"backend/creds/#paths","text":"The path category tag stores the absolute system paths for needed directories: basedir : the absolute base filesystem directory where your PCAPAnalyzer install is located.","title":"paths"},{"location":"backend/creds/#interfaces","text":"The interfaces category tag stores data about the listening system for packetstream : interface : the interface that the packetstream system listens on. it can be set to any of the interfaces on the system, but it can only have one value. It cannot be set to any .","title":"interfaces"},{"location":"backend/creds/#queryrunner","text":"The queryrunner category tag stores information needed for the queryrunner side of the web frontend: selectuser : The username on the PostgreSQL system that is only allowed to select data, from all of the PCAPAnalyzer databases. selectpassword : the password configured on install for the user mentioned above.","title":"queryrunner"},{"location":"backend/creds/#credchecking","text":"The credchecking category tag stores information needed to connect to the database that stores frontend accounts and API keys: user : the PostgreSQL install system user that can work with the pcapanalyzer_creds database to check and manage users and API keys. password : The PostgreSQL password for the user mentioned above. host : the database host where the PCAPAnalyzer install was made. Generally the same as the one on the client category tag. database : the name of the database where the system will look for credentials, generally pcapanalyzer_creds .","title":"credchecking"},{"location":"backend/packetstream/","text":"Packetstream data capture system To capture data into the packetstream database for analysis, PCAPAnalyzer uses the packetstream packend system. This is a python tool that will capture network data with wireshark in a constant loop as a background service, and will continually move it to a folder system for treatment. The streamlined data treatment workflow is as follows: Wireshark reads all closed .pcap files into a text file in a readable format, stripping away the binary format of the original .pcap file Python3 reads this csv file and does some data changes: merges the empty port columns inserts a column with the value of the local machineid credential entry transforms dates from linux epoch time into UTC ISO date format moves it to the last step In this last script, the data is copied into PostgreSQL with the psycopg2 connector for Python. This process is the same either if you are in the server where the frontend is installed, or in a system with the agent, with the difference that there has been some minor modifications in how the last step copies the data from the agents to the packetstream database. You can control this data gathering with systemd , thanks to the service file that was installed when you set up the environment. Just use systemctl {command} packetstream .","title":"packetstream"},{"location":"backend/packetstream/#packetstream-data-capture-system","text":"To capture data into the packetstream database for analysis, PCAPAnalyzer uses the packetstream packend system. This is a python tool that will capture network data with wireshark in a constant loop as a background service, and will continually move it to a folder system for treatment. The streamlined data treatment workflow is as follows: Wireshark reads all closed .pcap files into a text file in a readable format, stripping away the binary format of the original .pcap file Python3 reads this csv file and does some data changes: merges the empty port columns inserts a column with the value of the local machineid credential entry transforms dates from linux epoch time into UTC ISO date format moves it to the last step In this last script, the data is copied into PostgreSQL with the psycopg2 connector for Python. This process is the same either if you are in the server where the frontend is installed, or in a system with the agent, with the difference that there has been some minor modifications in how the last step copies the data from the agents to the packetstream database. You can control this data gathering with systemd , thanks to the service file that was installed when you set up the environment. Just use systemctl {command} packetstream .","title":"Packetstream data capture system"},{"location":"backend/pcapanalyzer-ids/","text":"PCAPAnalyzer Intrusion Detection System With all the captured data available on the PCAPAnalyzer system, you can use some python scrpting and SQL queries to form an intrusion detection system. This is a feature already implemented in your PCAPAnalyzer backend. You can access this by creating and editing probe files. These are python scripts that, every 30 minutes, will run as a background process on your main server and do whatever task they are programmed to do. In the provided examples you will see a proof of concept of how this can work, which is programmed to, by default, email the root@localhost user with a crafted message with the resulting SQL data. This feature works using the files under /{your PCAPAnalyzer install folder}/backend/intrusionDetection/ . Here you'll find three things: the start.py script, which controls running the service, the templates folder with some usage examples for the program, and the probes directory. Every script within this last one, by default, will run every 30 minutes. This intrusion detection system feature can be controlled through a systemd service file. You can use systemctl {command} pcapanalyzer-ids to start, stop, restart or reload the detection service as you see fit. To avoid double alerting, and because the data is centralized, this feature is only installed to the machine where you installed your full server install on first setup.","title":"PCAPAnalyzer IDS"},{"location":"backend/pcapanalyzer-ids/#pcapanalyzer-intrusion-detection-system","text":"With all the captured data available on the PCAPAnalyzer system, you can use some python scrpting and SQL queries to form an intrusion detection system. This is a feature already implemented in your PCAPAnalyzer backend. You can access this by creating and editing probe files. These are python scripts that, every 30 minutes, will run as a background process on your main server and do whatever task they are programmed to do. In the provided examples you will see a proof of concept of how this can work, which is programmed to, by default, email the root@localhost user with a crafted message with the resulting SQL data. This feature works using the files under /{your PCAPAnalyzer install folder}/backend/intrusionDetection/ . Here you'll find three things: the start.py script, which controls running the service, the templates folder with some usage examples for the program, and the probes directory. Every script within this last one, by default, will run every 30 minutes. This intrusion detection system feature can be controlled through a systemd service file. You can use systemctl {command} pcapanalyzer-ids to start, stop, restart or reload the detection service as you see fit. To avoid double alerting, and because the data is centralized, this feature is only installed to the machine where you installed your full server install on first setup.","title":"PCAPAnalyzer Intrusion Detection System"},{"location":"frontend/about/","text":"About PCAPAnalyzer developer credit and licensing On the about page of PCAPAnalyzer you will find some information about the project, and some frontend management settings. First you can see information about the software version, licensing details, and developer credit. Identity and Access Management You can also change the frontend page css for your session between the light and dark themes. On the bottom of this page, you will find two identity and access management options: one to create and delete users to access the frontend webapp, and one for managing API secrets for API requests. User management On this site, you can either create custom users and passwords to insert into the pcapanalyzer_creds database on the users table, or you can drop existing users under this form. Keep in mind, you are not allowed to drop all of the users on the system: there has to be at least one. API management On this page you can generate new API keys, stored on the pcapanalyzer_creds database under the apikeys table, or drop API keys. If you want to, you can drop all of the API keys so no one has possible access to the API.","title":"about"},{"location":"frontend/about/#about-pcapanalyzer","text":"","title":"About PCAPAnalyzer"},{"location":"frontend/about/#developer-credit-and-licensing","text":"On the about page of PCAPAnalyzer you will find some information about the project, and some frontend management settings. First you can see information about the software version, licensing details, and developer credit.","title":"developer credit and licensing"},{"location":"frontend/about/#identity-and-access-management","text":"You can also change the frontend page css for your session between the light and dark themes. On the bottom of this page, you will find two identity and access management options: one to create and delete users to access the frontend webapp, and one for managing API secrets for API requests.","title":"Identity and Access Management"},{"location":"frontend/about/#user-management","text":"On this site, you can either create custom users and passwords to insert into the pcapanalyzer_creds database on the users table, or you can drop existing users under this form. Keep in mind, you are not allowed to drop all of the users on the system: there has to be at least one.","title":"User management"},{"location":"frontend/about/#api-management","text":"On this page you can generate new API keys, stored on the pcapanalyzer_creds database under the apikeys table, or drop API keys. If you want to, you can drop all of the API keys so no one has possible access to the API.","title":"API management"},{"location":"frontend/database-picker/","text":"Database picker When you click on the menu entry for Current database , you will be redirected to the database management page. In this site, you will get two different options: you can either change what database you want to use for analysis, or you can delete databases when you're done with them. On the first option, you need to pick the database you want to see the data of from the drop-down menu, then click confirm . The app will then redirect you to the system homepage with your new database as the active data source. If you're done with a database and you want to delete it from the system, use the lower form. Select the database you wanna drop, then click drop . The database will be deleted, and you will be redirected to the homepage with packetstream as the new data source database.","title":"database picker"},{"location":"frontend/database-picker/#database-picker","text":"When you click on the menu entry for Current database , you will be redirected to the database management page. In this site, you will get two different options: you can either change what database you want to use for analysis, or you can delete databases when you're done with them. On the first option, you need to pick the database you want to see the data of from the drop-down menu, then click confirm . The app will then redirect you to the system homepage with your new database as the active data source. If you're done with a database and you want to delete it from the system, use the lower form. Select the database you wanna drop, then click drop . The database will be deleted, and you will be redirected to the homepage with packetstream as the new data source database.","title":"Database picker"},{"location":"frontend/dataglance/","text":"dataGlance When you need quick info about some specific data, you can use dataGlance . This page provides tables with frequently consulted data: Private range IPs found Public range IPs found MAC addresses seen protocols registered Well-known ports Ports over 1024 that are not dynamic This data is refreshed every time you reload the page, and it is dependant on the database you're currently analyzing. This data is also available through the API .","title":"dataGlance"},{"location":"frontend/dataglance/#dataglance","text":"When you need quick info about some specific data, you can use dataGlance . This page provides tables with frequently consulted data: Private range IPs found Public range IPs found MAC addresses seen protocols registered Well-known ports Ports over 1024 that are not dynamic This data is refreshed every time you reload the page, and it is dependant on the database you're currently analyzing. This data is also available through the API .","title":"dataGlance"},{"location":"frontend/dbcreator/","text":"dbCreator analysis database generator Apart from the packetstream data capture system, you can also upload your own .pcap files for the PCAPAnalyzer system to generate analysis databases with. On this form, you will input a database name, then upload all of your .pcap files to read into the system. Once this is done, click on Create new database for the system to start the process. This page will stay loading until the process is done. Do not close the page until you are redirected to the system's homepage. Keep in mind that depending on the size of your .pcap files and system performance, this process could take some time to complete. You can upload, at most, 100 megabyte individual files, or a total of 200 megabytes of data. Once the database creation process is complete, you can proceed to the database picker and start doing data analysis on your new database.","title":"dbCreator"},{"location":"frontend/dbcreator/#dbcreator-analysis-database-generator","text":"Apart from the packetstream data capture system, you can also upload your own .pcap files for the PCAPAnalyzer system to generate analysis databases with. On this form, you will input a database name, then upload all of your .pcap files to read into the system. Once this is done, click on Create new database for the system to start the process. This page will stay loading until the process is done. Do not close the page until you are redirected to the system's homepage. Keep in mind that depending on the size of your .pcap files and system performance, this process could take some time to complete. You can upload, at most, 100 megabyte individual files, or a total of 200 megabytes of data. Once the database creation process is complete, you can proceed to the database picker and start doing data analysis on your new database.","title":"dbCreator analysis database generator"},{"location":"frontend/homepage/","text":"Web frontend homepage THe homepage presents a table with quick information about data on every database on the PCAPAnalyzer data management system. For every logging database, you get information about: The total number of stored packets on the database The number of data sources or agents logged (only available for packetstream ) The number of external IPs contacted How many different MACs have been found on the registry How many of the total packets were multicast How many different protocols were registered in the system This table is generated again every time you reload the homepage. This data is also available through the API .","title":"homepage"},{"location":"frontend/homepage/#web-frontend-homepage","text":"THe homepage presents a table with quick information about data on every database on the PCAPAnalyzer data management system. For every logging database, you get information about: The total number of stored packets on the database The number of data sources or agents logged (only available for packetstream ) The number of external IPs contacted How many different MACs have been found on the registry How many of the total packets were multicast How many different protocols were registered in the system This table is generated again every time you reload the homepage. This data is also available through the API .","title":"Web frontend homepage"},{"location":"frontend/login/","text":"Frontend login Once you open the web frontend for your install, you will be greeted by a login screen. If this is your first time, you'll have to provide the web login credentials given to you by the installer script. Once you're inside the web frontend, you can create new users with your own passwords (see \"about\") at the end of this Frontend documentation category. The default username for the web frontend upon install is admin . The password is randomly generated for every install and is only output in plaintext once by the install script. These web frontend passwords are stored in the database, in bcrypt hash format using the blowfish non-cryptographically reversible algorithm. Once a password is sent in the form with a post request, the check script will check the username and password on the system. If the user does not exist or you submitted a wrong username and password, you will be redirected back to the login form with an error message. If the username exists on the pcapanalyzer_creds database inside of the users table, and the bcrypt hash matches the one calculated on the frontend form, you will be redirected to the PCAPAnalyzer frontend homepage.","title":"login"},{"location":"frontend/login/#frontend-login","text":"Once you open the web frontend for your install, you will be greeted by a login screen. If this is your first time, you'll have to provide the web login credentials given to you by the installer script. Once you're inside the web frontend, you can create new users with your own passwords (see \"about\") at the end of this Frontend documentation category. The default username for the web frontend upon install is admin . The password is randomly generated for every install and is only output in plaintext once by the install script. These web frontend passwords are stored in the database, in bcrypt hash format using the blowfish non-cryptographically reversible algorithm. Once a password is sent in the form with a post request, the check script will check the username and password on the system. If the user does not exist or you submitted a wrong username and password, you will be redirected back to the login form with an error message. If the username exists on the pcapanalyzer_creds database inside of the users table, and the bcrypt hash matches the one calculated on the frontend form, you will be redirected to the PCAPAnalyzer frontend homepage.","title":"Frontend login"},{"location":"frontend/packetstream/","text":"PCAPAnalyzer PacketStream The PacketStream tab allows you to look at every network packet that is logged on the database. For every packet registered on the system you can see: a UTC timestamp the machine ID that provided the data [!] only available on the packetstream database Source MAC address Destination MAC address Source IP address Destination IP address Protocol used Source port Destination port packet content info This data is reverse indexed and ordered by entry id, so retrieval is as fast as possible. Then, on top of this table, you see a filter set form. In this form, you can input a value for any of the columns stated as a filter. You can use as many filters as you need, but keep in mind they work in an AND basis: a packet has to fit all of your filter criteria to appear on the table. Once all of your filters are set, you will need to click apply filters to apply them. If you want to reset all your set filters, you can use the reset filters button.","title":"packetStream"},{"location":"frontend/packetstream/#pcapanalyzer-packetstream","text":"The PacketStream tab allows you to look at every network packet that is logged on the database. For every packet registered on the system you can see: a UTC timestamp the machine ID that provided the data [!] only available on the packetstream database Source MAC address Destination MAC address Source IP address Destination IP address Protocol used Source port Destination port packet content info This data is reverse indexed and ordered by entry id, so retrieval is as fast as possible. Then, on top of this table, you see a filter set form. In this form, you can input a value for any of the columns stated as a filter. You can use as many filters as you need, but keep in mind they work in an AND basis: a packet has to fit all of your filter criteria to appear on the table. Once all of your filters are set, you will need to click apply filters to apply them. If you want to reset all your set filters, you can use the reset filters button.","title":"PCAPAnalyzer PacketStream"},{"location":"frontend/queryrunner/","text":"queryRunner SQL form In the queryRunner tab of the web fronend, you get a text field where you can write your own SQL SELECT query, in the event that the packetstream table is limited for your needs. You need to write your SQL query inside of the text field on the page (as specified, the data table is always named main ), and when it's done, click on the Run query button to run it. Once done, your browser will prompt you to download a CSV file with your data. The database that the query runs on is dependent on what is your current session's selected database to work with, indicated on the top menu bar, on the Current database menu button. This input field will only run SELECT queries on the selected database. Any other query order type will return an error.","title":"queryRunner"},{"location":"frontend/queryrunner/#queryrunner-sql-form","text":"In the queryRunner tab of the web fronend, you get a text field where you can write your own SQL SELECT query, in the event that the packetstream table is limited for your needs. You need to write your SQL query inside of the text field on the page (as specified, the data table is always named main ), and when it's done, click on the Run query button to run it. Once done, your browser will prompt you to download a CSV file with your data. The database that the query runs on is dependent on what is your current session's selected database to work with, indicated on the top menu bar, on the Current database menu button. This input field will only run SELECT queries on the selected database. Any other query order type will return an error.","title":"queryRunner SQL form"},{"location":"getting-started/installation/","text":"Installing the server Once all of the system requirements are met, you can proceed on installing your environment. First, you need to setup the main server environment. Server install To install the server environment: git clone the PCAPAnalyzer installer repo cd to the cloned repo on the pcapanalyzer folder Navigate to the install folder Run the installer.py script with python3 installer.py When prompted, enter s or S to perform a full server install. You will be asked to input a machineid. Choose a unique identifier for the host, like its hostname. Input the directory where you want the system to be installed. This directory needs to be inside one of your webroots accessible by apache2 . Input the postgresql admin user to create the environment. input the admin postgresql user password used to remotely connect to the system [!] The password is not visible in plaintext in the terminal in this step while you write it. Be careful . Input the IP address where the postgresql install is set up Input the domain that the apache2 virtualhost will listen on. From the listed options, provide the system name of the interface you want the network sniffer to listen on. [!] you can only have one listen entry. It cannot be set to any . When the install is done, you will be provided with the pcapanalyzer agent password. Save this password, because it will be stored on the .my.cnf file, and you will probably need it later. You will be given a web frontend password for the admin account. save these credentials , because they are only stored on the database with a non-reversible cryptography algorithm and is not retrievable otherwise. If you want to, enable data logging on the PCAPAnalyzer server with service packetstream start . Once this installation is complete, you will have a functional PCAPAnalyzer install to use. To capture data from other machines, continue to the next section. The resulting permission structure should be as follows:","title":"Installation"},{"location":"getting-started/installation/#installing-the-server","text":"Once all of the system requirements are met, you can proceed on installing your environment. First, you need to setup the main server environment.","title":"Installing the server"},{"location":"getting-started/installation/#server-install","text":"To install the server environment: git clone the PCAPAnalyzer installer repo cd to the cloned repo on the pcapanalyzer folder Navigate to the install folder Run the installer.py script with python3 installer.py When prompted, enter s or S to perform a full server install. You will be asked to input a machineid. Choose a unique identifier for the host, like its hostname. Input the directory where you want the system to be installed. This directory needs to be inside one of your webroots accessible by apache2 . Input the postgresql admin user to create the environment. input the admin postgresql user password used to remotely connect to the system [!] The password is not visible in plaintext in the terminal in this step while you write it. Be careful . Input the IP address where the postgresql install is set up Input the domain that the apache2 virtualhost will listen on. From the listed options, provide the system name of the interface you want the network sniffer to listen on. [!] you can only have one listen entry. It cannot be set to any . When the install is done, you will be provided with the pcapanalyzer agent password. Save this password, because it will be stored on the .my.cnf file, and you will probably need it later. You will be given a web frontend password for the admin account. save these credentials , because they are only stored on the database with a non-reversible cryptography algorithm and is not retrievable otherwise. If you want to, enable data logging on the PCAPAnalyzer server with service packetstream start . Once this installation is complete, you will have a functional PCAPAnalyzer install to use. To capture data from other machines, continue to the next section. The resulting permission structure should be as follows:","title":"Server install"},{"location":"getting-started/post-install/","text":"Installing the agent When you already have a full server install, you may want to install the agent on host machines to gather data from them. The install steps for the agent are: git clone the PCAPAnalyzer installer repo cd to the cloned repo on the pcapanalyzer folder Navigate to the install folder Run the installer.py script with python3 installer.py when prompted for a confirmation, choose y or Y to enter the install script When prompted, enter a or A to perform an agent install. Input the postgresql database manager host IP that has the PCAPAnalyzer database install from your server. input the password that the server install generated for your PCAPAgent user. You will be asked to input a machineid. Choose a unique identifier for the host, like its hostname. input the absolute path where you want to install the agent. The team's recommendation is /opt/pcapagent/ . From the listed options, provide the system name of the interface you want the network sniffer to listen on. [!] YOu can only have one listen entry. You cannot set it to any . Enable the data logging with service packetstream start . Once this installation is complete, you will have a functional PCAPAnalyzer install to use.","title":"Post-install"},{"location":"getting-started/post-install/#installing-the-agent","text":"When you already have a full server install, you may want to install the agent on host machines to gather data from them. The install steps for the agent are: git clone the PCAPAnalyzer installer repo cd to the cloned repo on the pcapanalyzer folder Navigate to the install folder Run the installer.py script with python3 installer.py when prompted for a confirmation, choose y or Y to enter the install script When prompted, enter a or A to perform an agent install. Input the postgresql database manager host IP that has the PCAPAnalyzer database install from your server. input the password that the server install generated for your PCAPAgent user. You will be asked to input a machineid. Choose a unique identifier for the host, like its hostname. input the absolute path where you want to install the agent. The team's recommendation is /opt/pcapagent/ . From the listed options, provide the system name of the interface you want the network sniffer to listen on. [!] YOu can only have one listen entry. You cannot set it to any . Enable the data logging with service packetstream start . Once this installation is complete, you will have a functional PCAPAnalyzer install to use.","title":"Installing the agent"},{"location":"getting-started/prerequisites/","text":"Installation prerequisites Before you can set up a PCAPAnalyzer installation, you need to have a ready environment with the next elements: Server install This is the full server install that sets up the entire environment as front-end and back-end services for data gathering. You need to start with this one. Python3 is installed on your system You're running a system with Debian 10 or greater This system has access to the internet This system has at least 1 gigabyte of ram and a dual-core CPU This system has an active apache2 install, it can be a fresh one. You have administrator credentials to a local or remote PostgreSQL server You have administrator credentials for the machine and you're running the script as root A domain to point this website towards. It can be a local internal name. Agent install If you already have a full server install, you can install the agent on host machines to gather data from them. The prerequisites for the agent are: Python3 is installed on your system You're running a system with Debian 10 or greater This system has access to the internet This system has at least 1 gigabyte of ram and a dual-core CPU You have the agent login credentials given to you during the server install You have administrator credentials for the machine and you're running the script as root Once this setup is confirmed, you can proceed to installing the server.","title":"Prerequisites"},{"location":"getting-started/prerequisites/#installation-prerequisites","text":"Before you can set up a PCAPAnalyzer installation, you need to have a ready environment with the next elements:","title":"Installation prerequisites"},{"location":"getting-started/prerequisites/#server-install","text":"This is the full server install that sets up the entire environment as front-end and back-end services for data gathering. You need to start with this one. Python3 is installed on your system You're running a system with Debian 10 or greater This system has access to the internet This system has at least 1 gigabyte of ram and a dual-core CPU This system has an active apache2 install, it can be a fresh one. You have administrator credentials to a local or remote PostgreSQL server You have administrator credentials for the machine and you're running the script as root A domain to point this website towards. It can be a local internal name.","title":"Server install"},{"location":"getting-started/prerequisites/#agent-install","text":"If you already have a full server install, you can install the agent on host machines to gather data from them. The prerequisites for the agent are: Python3 is installed on your system You're running a system with Debian 10 or greater This system has access to the internet This system has at least 1 gigabyte of ram and a dual-core CPU You have the agent login credentials given to you during the server install You have administrator credentials for the machine and you're running the script as root Once this setup is confirmed, you can proceed to installing the server.","title":"Agent install"}]}